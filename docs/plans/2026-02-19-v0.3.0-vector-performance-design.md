# Audrey v0.3.0 — Vector Performance Design

**Date:** 2026-02-19
**Status:** Approved
**Author:** Tyler Eveland + Claude

---

## Goal

Replace all JavaScript-side vector operations with native sqlite-vec queries. Eliminate embedding duplication, push filtering into SQL, fix O(N^2) clustering, add batch encoding and streaming recall. After v0.3.0, all vector math runs in C, JS only handles confidence scoring on small candidate sets.

## Scope

**In scope:**
- sqlite-vec virtual tables as primary vector store
- SQL-native KNN for recall, validation, and clustering
- Metadata filtering in KNN queries (state, source, consolidated)
- Batch encoding with single embedding API call
- Streaming recall via async generators
- Migration from BLOB columns to vec0 tables

**Deferred (v0.4.0+):**
- Embedding migration pipeline (re-embed when models change)
- Re-consolidation queue
- ANN indexing (sqlite-vec is brute-force only; adequate to ~100k vectors)

---

## 1. sqlite-vec Integration

### Extension Loading

Load sqlite-vec in `db.js` at database creation time:

```js
import * as sqliteVec from 'sqlite-vec';
sqliteVec.load(db);
```

This registers the `vec0` virtual table module and all `vec_distance_*` scalar functions.

### Dimension Configuration

vec0 tables require dimensions at creation time. The database stores the configured dimension in a new `audrey_config` table:

```sql
CREATE TABLE IF NOT EXISTS audrey_config (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL
);
```

On first `createDatabase(dataDir, { dimensions })` call, dimensions are persisted. Subsequent calls validate that the stored dimensions match the provider's dimensions, throwing if mismatched (prevents silent corruption from swapping embedding models without migration).

---

## 2. vec0 Virtual Tables

### Schema

```sql
CREATE VIRTUAL TABLE IF NOT EXISTS vec_episodes USING vec0(
  id text primary key,
  embedding float[{dimensions}] distance_metric=cosine,
  source text,
  consolidated integer
);

CREATE VIRTUAL TABLE IF NOT EXISTS vec_semantics USING vec0(
  id text primary key,
  embedding float[{dimensions}] distance_metric=cosine,
  state text
);

CREATE VIRTUAL TABLE IF NOT EXISTS vec_procedures USING vec0(
  id text primary key,
  embedding float[{dimensions}] distance_metric=cosine,
  state text
);
```

Metadata columns enable SQL-native filtering during KNN scans. sqlite-vec supports `=`, `!=`, `>`, `<`, `>=`, `<=`, `IN` on metadata columns.

### Write Path

All embedding writes go to vec0 tables. The main tables (episodes, semantics, procedures) retain all non-vector columns. The `embedding BLOB` column on main tables stops receiving writes (kept for backwards compatibility; removed in a future schema migration version).

**Encode:** Insert into `episodes` (no embedding) + `vec_episodes` (embedding + metadata).
**Consolidate:** Insert into `semantics` (no embedding) + `vec_semantics` (embedding + state).
**Causal/Procedural:** Same pattern.

### Read Path

All vector searches use vec0 KNN, then JOIN to the main table for full row data.

### Migration

On database open, if vec0 tables don't exist but main tables have embedding BLOBs, run a one-time migration:

```sql
INSERT INTO vec_episodes(id, embedding, source, consolidated)
SELECT id, embedding, source, consolidated FROM episodes WHERE embedding IS NOT NULL;
```

Same for semantics and procedures. This is idempotent — if vec0 tables already have data, skip.

---

## 3. Recall Rewrite

### Current: O(N) full scan in JS

```js
const episodes = db.prepare('SELECT * FROM episodes WHERE ...').all();
for (const ep of episodes) {
  const similarity = cosineSimilarity(queryBuffer, ep.embedding, provider);
  // ...
}
```

### New: KNN in C, confidence scoring on K candidates

```sql
-- Episodic recall
SELECT e.*, (1.0 - v.distance) AS similarity
FROM vec_episodes v
JOIN episodes e ON e.id = v.id
WHERE v.embedding MATCH ?queryVector
  AND k = ?candidateK
  AND v.consolidated = 0;

-- Semantic recall
SELECT s.*, (1.0 - v.distance) AS similarity
FROM vec_semantics v
JOIN semantics s ON s.id = v.id
WHERE v.embedding MATCH ?queryVector
  AND k = ?candidateK
  AND v.state IN ('active', 'context_dependent');
```

JS receives at most `candidateK` rows per type, computes confidence scores, re-ranks by `similarity * confidence`, and returns top `limit`.

`candidateK` should be larger than `limit` to account for confidence-based re-ranking (e.g., `candidateK = limit * 3`).

### Retrieval Reinforcement

Still happens in JS after scoring — increment `retrieval_count` on matched semantic/procedural IDs. No change to this logic.

---

## 4. Validation Rewrite

### Current: O(N) scan all active semantics

### New: Single KNN query

```sql
SELECT s.id, s.content, (1.0 - v.distance) AS similarity
FROM vec_semantics v
JOIN semantics s ON s.id = v.id
WHERE v.embedding MATCH ?episodeVector
  AND k = 1
  AND v.state IN ('active', 'context_dependent');
```

Returns the single closest semantic memory. JS checks which zone the similarity falls into:
- `>= 0.85`: reinforce
- `>= 0.60` with LLM: contradiction check
- `< 0.60`: no action

The episode's vector is queried from vec_episodes (already inserted during encode) rather than re-embedded.

---

## 5. Clustering Rewrite

### Current: O(N^2) pairwise cosine in JS

```js
for (let i = 0; i < n; i++) {
  for (let j = i + 1; j < n; j++) {
    const sim = cosineSimilarity(episodes[i].embedding, episodes[j].embedding, provider);
    if (sim >= threshold) union(i, j);
  }
}
```

### New: N KNN queries in C + Union-Find in JS

For each unconsolidated episode, find its nearest neighbors within the unconsolidated set:

```sql
SELECT v.id, (1.0 - v.distance) AS similarity
FROM vec_episodes v
WHERE v.embedding MATCH (SELECT embedding FROM vec_episodes WHERE id = ?)
  AND k = ?maxNeighbors
  AND v.consolidated = 0;
```

Filter results where `similarity >= threshold`. Build edge list. Run Union-Find on edges.

This replaces N^2/2 JS cosine computations with N native KNN queries. Each KNN query scans only unconsolidated episodes (filtered by metadata). The Union-Find algorithm remains in JS — it's O(N * alpha(N)) which is effectively linear.

---

## 6. Batch Encoding

### New API

```js
const ids = await brain.encodeBatch([
  { content: 'Observation 1', source: 'direct-observation' },
  { content: 'Observation 2', source: 'tool-result' },
  { content: 'Observation 3', source: 'told-by-user' },
]);
```

### Embedding Provider Changes

Add `embedBatch(texts)` to the provider interface:

- **MockEmbeddingProvider:** Maps over `embed()` — no real batching needed.
- **OpenAIEmbeddingProvider:** Single API call with `input: [text1, text2, ...]`. OpenAI accepts up to 2048 inputs per request.

### Implementation

1. Call `embeddingProvider.embedBatch(contents)` — one API round-trip
2. Single SQLite transaction: insert all episode rows + all vec_episodes rows
3. Fire `encode` events for each episode
4. Kick off async validation for each (non-blocking, same as current)
5. Return array of IDs

---

## 7. Streaming Recall

### New API

```js
for await (const memory of brain.recallStream('stripe rate limit', { limit: 5 })) {
  console.log(memory.content, memory.score);
  if (memory.score > 0.9) break; // early exit
}
```

### Implementation

Async generator that:
1. Runs KNN queries (same SQL as recall rewrite)
2. Yields scored results one at a time
3. Consumer can `break` early without processing remaining candidates

The non-streaming `recall()` method is rewritten to consume the stream internally, maintaining backwards compatibility.

---

## 8. File Changes

| File | Change |
|------|--------|
| `src/db.js` | Load sqlite-vec extension, create vec0 tables, dimension config, migration |
| `src/encode.js` | Write to vec_episodes instead of embedding BLOB |
| `src/recall.js` | KNN queries + confidence scoring on candidates, streaming generator |
| `src/validate.js` | KNN k=1 for nearest semantic match |
| `src/consolidate.js` | N KNN clustering, write to vec_semantics |
| `src/embedding.js` | Add `embedBatch()` to all providers |
| `src/audrey.js` | Add `encodeBatch()`, `recallStream()`, pass dimensions to db |
| `src/index.js` | Export new methods |
| `src/utils.js` | Remove `cosineSimilarity` (no longer needed from JS) |

## 9. Testing Strategy

### New test files
- `tests/vec.test.js` — sqlite-vec loading, vec0 table creation, KNN queries, migration

### Modified test files
- `tests/recall.test.js` — Verify KNN-based recall produces same results as brute-force
- `tests/validate.test.js` — Verify KNN validation matches previous behavior
- `tests/consolidate.test.js` — Verify KNN clustering produces same clusters
- `tests/encode.test.js` — Verify dual-write to episodes + vec_episodes
- `tests/embedding.test.js` — Test embedBatch()
- `tests/audrey.test.js` — Test encodeBatch(), recallStream()

### Backwards compatibility

All existing tests must continue to pass. The behavioral contract doesn't change — same inputs produce equivalent outputs. Only the performance characteristics change.

### Migration test

Verify that a database created with v0.2.0 (embedding BLOBs, no vec0) migrates correctly on first open with v0.3.0.

---

## 10. Performance Expectations

| Operation | v0.2.0 | v0.3.0 |
|-----------|--------|--------|
| Recall (1k episodes) | ~1k cosine computations in JS | 1 KNN query in C |
| Validation | Full scan of all semantics in JS | KNN k=1 in C |
| Clustering (100 episodes) | ~5k pairwise cosines in JS | 100 KNN queries in C |
| Encode 50 episodes | 50 API calls | 1 batch API call |

sqlite-vec brute-force on float32 vectors handles ~100k vectors with sub-10ms latency for typical embedding dimensions (384-1536). This matches Audrey's documented scale boundary.
